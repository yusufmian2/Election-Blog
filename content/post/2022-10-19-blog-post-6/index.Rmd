---
title: Blog Post 6
author: Yusuf Mian
date: '2022-10-19'
slug: []
categories: []
tags: []
---
## The Ground Game

<br>
This week, we will delving into the ground game. To do this, I will be looking at turnout mostly along with some other aspects as well as talking about my model.
<br>

The first thing I wanted to explore with turnout was to consider the common "myth" in political science that higher turnout benefits Democrats. To do this, I took a look at the Citizen Voting Age Population (CVAP) data available by district from 2012 to 2020 and compared it to the actual turnout. I chose to calculate turnout by simply adding the total votes for Democrats and Republicans. While this does not account for third party voters, the reason I am using this as turnout is both because of available data and because my model considers only Democratic and Republican voters so as a relative comparison I found this appropriate. That being said, this is potentially a challenge of the model.
<br>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
setwd("/Users/yusufmian/Desktop/Election Analysis/Election-Blog")
library(tidyverse); library(knitr)
polls2022 <- read.csv("538_house_polls_2022.csv")
pvi <- read.csv("PVI_share.csv")
house_party_vote_share_by_district_1948_2020 <- read.csv("house party vote share by district 1948-2020.csv")
h <- house_party_vote_share_by_district_1948_2020
cvap_district <- read_csv("cvap_district_2012-2020_clean.csv")
polls_df <- read_csv("house_polls_long.csv")
expert_ratings <- read.csv("expert_rating.csv")
ad_creative  <- read_csv("ads_2006_2018 (1).csv")
library(tidyverse)
library(stargazer)
rdi_df <- read.csv("rdi_quarterly.csv")
gdp_df <- read.csv("GDP_quarterly.csv")
housevoteshare <- read.csv("house_popvote_seats.csv")
econdata <- left_join ( housevoteshare, gdp_df, by="year")

```
As you can see in the first model below, turnout did not have any meaningful prediction of Democratic Predicted Vote Share. The model said with no statistical significance that there would be a small increase in Democratic Vote Share as turnout increased, but as you can see, the R-Squared and Adjusted R-squared are very low and the model does not seem to have much predictive power. I considered using dummy values of potential turnout for 2022 to come up with some predictions, but I opted not do this because the model had such little predictive power. For this reason, I also will NOT be using turnout in my National or District level model. Part of the reason I think the model was so poor is because of the lack of data. However, I also think that turnout is subject to the environment and does not necessarily benefit one party or the other. If the Democratic base is energized, but the Republican voters turnout in low numbers, the turnout may be low, but Democrats will still do well. We can think of many analogous scenarios were turnout overall does not help us to understand the actual result of the election.
```{r}
hcvap <- h %>% 
  filter(raceYear>=2012) %>% 
  rename(year=raceYear)
cvap <- cvap_district %>% 
  mutate(cd=as.numeric(cd)) %>% 
  rename(State=state, district_num=cd)
hturnout <- full_join(cvap, hcvap, by=c("year", "State", "district_num"))
hturnout <- hturnout %>% 
  mutate(turnout=(DemVotes + RepVotes)/cvap)
turnoutlm <- lm(DemVotesMajorPercent ~ turnout, data=hturnout)
stargazer(turnoutlm, type="text")
```

<br>
Next, I considered taking a look at if turnout was impacted by the number of ads run. I think this could have been an interesting model for two reasons. First, as we saw last week, ads was not very useful in predicting the results of elections. However, intuitively, it seems like the number of ads run should have some impact on turnout. Even if we can't use total turnout to predict election results, turnout is still an interesting thing to consider, so we could have some use if we thought the number of ads could predict turnout.
<br>
However, as you can see below, again, the adjusted and regular R-squared values are so low that it is very to difficult to fit a model, so I again opted against fitting a model using these factors.

```{r}
ad_creative$district <- as.integer(ad_creative$district)
ad_creative2 <- ad_creative %>% 
  mutate(count=1) %>% 
  group_by(cycle, state, district, party) %>% 
  summarise(districtAdNumber= sum(count)) %>% 
  filter(party=="Democrat" | party=="Republican") %>% 
  drop_na(district) %>% 
  rename(State=state, district_num=district, year=cycle)
adturnout <- full_join(hturnout, ad_creative2, by=c("State", "year", "district_num"))
adturnoutlm <- lm(turnout~ districtAdNumber, data=adturnout)
stargazer(adturnoutlm, type="text")
```

<br>
UPDATES TO THE MODEL FOR THE WEEK
<br>
I want to get into my model for the week and the changes I made, but I first would like to show one of the things I incorporated into the model for this week. As I discussed a few weeks back, when I attempted to incorporate expert predictions into my national model, I had trouble thinking about how they factored into the eventual national results, so I had to devise a method of converting predictions into vote share outcomes. However, this week, I opted to fit a district level model using district level expert predictions that we have available. Even though we only have 2 years of predictions, because each district is a different data point, we actually have lots of predictions. I was able to fit a relatively good model using ratings, which you can see below is both statistically significant and has a relatively high R-Squared.
<br>
```{r}
h2<- h %>% 
  filter(raceYear==2020 | raceYear==2018) %>% 
  rename(year=raceYear)
polls_dfModel <- polls_df %>% 
  mutate(year = ifelse(year%%2!=0, year+1, year)) %>% 
  filter(year!=2022) %>% 
  mutate(cd_fips= as.numeric(cd_fips), st_fips=as.numeric(st_fips), DEM=as.numeric(DEM)) %>% 
  rename(district_num=cd_fips)
pollShare <- full_join(polls_dfModel, h2, by=c("year", "st_fips", "district_num"))
districtpollLM <- lm(DemVotesMajorPercent ~ DEM, data=pollShare)
h2022 <- h %>% 
  filter(raceYear==2022) %>% 
  rename(year=raceYear)
polls2022Dem <- polls2022 %>% 
  filter(party=="DEM") %>% 
  rename(DEM=pct)
polls2022Michigan <- polls2022Dem %>% 
  filter(st_fips==26 & cd_fips==10)
mi10pollingprediction <-mean(predict(districtpollLM, polls2022Michigan))
expert_ratingsModel <- expert_ratings %>% 
  filter(year!=2022) %>% 
  mutate(district=as.numeric(district))
h3 <- h %>% 
  filter(raceYear>=2010) %>% 
  rename(year=raceYear, state=State, district=district_num)
expertShare <- full_join(expert_ratingsModel, h3, by=c("year", "state", "district"))
districtexpertLM <- lm(DemVotesMajorPercent~avg_rating, data=expertShare)
stargazer(districtexpertLM, type="text")
```

For the model this week, I actually made no new changes to the national model, which is still the same as before and can be seen on other blog posts. It predicts a Democratic loss nationally by around 2 percentage points. However, even though I was not adding new data like ads or turnout because I didn't find that predictive, I am making a new type of model. I am showing my district level model by taking out one district of interest. Later on and after the election, I will be exploring Michigan's 10th Congressional District and thinking about the events that happened in the campaign. I will be trying to reflect on how my model may have failed to succeeded in predicting this specific race and think about why that was. For this reason, I am showing a district level model which I have put data from MI-10 into to predict the race.
<br>
For this district level model, even though it is the same data, there are some new things to consider. First, now that I am using district polls, which are less often and less accurate, the predictivity is not as high for polling in this model as the national model. Second, the economic data is still the national economic data since there is no available at the district level. Third, I am obviously only using the Cook PVI data for this district and not a national average. Finally, as I explained above, I am using the new model for the Expert Prediction and plugging in the 2022 expert predictions for MI-10.
```{r}
mi10expert <- expert_ratings %>% 
  filter(year==2022 & state=="Michigan" & district==10) %>% 
  select(avg_rating)
mi10expertPrediction <- predict(districtexpertLM, mi10expert)
pviMichigan <- pvi %>% 
  filter(District=="Michigan 10")
pvilm <- 50+((pviMichigan$PVI_num)/2)

econ <- econdata %>% 
  filter(year%%4!=0, quarter_cycle=="5")
lm_gdp <- lm(H_incumbent_party_majorvote_pct ~ GDPC1, data=econ)
gdpVotenew <-gdp_df %>% 
  filter(year==2022, quarter_cycle=="5") %>% 
  select(GDPC1)
gdpPrediction <- predict(lm_gdp, gdpVotenew)
expertRsquared <- summary(districtexpertLM)$r.squared
gdpRsquared<- summary(lm_gdp)$r.squared
mi10Prediction <- mean((0.3*pvilm) + (0.3* mi10expertPrediction) + (0.2*mi10pollingprediction) +0.2*(gdpPrediction))
table2 <- matrix(c(mi10Prediction, " ",  pvilm, "NA", mi10expertPrediction, expertRsquared, mean(mi10pollingprediction), "Low", gdpPrediction, gdpRsquared), ncol=2, byrow=TRUE)
rownames(table2) <- c('Overall Prediction', 'PVI (0.3)', "Expert Prediction(0.3)", "Polling Prediction (0.2)", "Economy Prediction (0.2)")
colnames(table2) <- c("Prediction", "R-Squared")
stargazer(table2, title="Michigan 10th Congressional District Democratic Predicted Vote Share)", type="text")
  
```
