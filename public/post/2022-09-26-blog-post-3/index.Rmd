---
title: "Blog Post 3"
author: "Yusuf Mian"
date: '2022-09-26'
output: pdf_document
categories: []
tags: []
slug: []
---
## Polling trends and  predicting elections
<br>
This week, we will be diving into polling and using polling along with the economic fundamentals from last week to update my model and predicitons for the 2022 elections. However, before I get into the choices I have made in my own predictions for the election, I am going to be taking a deeper dive into some of the decisions that went into two of the most well known models that exist for election predictions. These models are from Nate Silver, who is the data guru behind the well known site 538, and G. Elliott Morris, who is a data scientist that works on the election models for the Economist.
<br>
First, we are going to start with Nate Silver's model. Silver has become very well known for his forecasting models for House, Senate, and Presidential elections as well as his very easy to understand graphics which many in the media rely on for updating the elections before they happen. 
<br>
Silver, who has pointed out that his model has largely been the same type of model since 2018, for House, Senate, and even Gubernatorial elections, has consistency in his approach. In the most advanced model, 538 uses polling, economic fundamentals, expert forecasts (from organizations like Cook Political which give ratings for every district), and a system 538 has in their modeling to model districts that have little polling by comparing to similar districts. This is important to note because while our model may not have all of the features of a leading prediction like 538, at its heart we both are using some form of polling and both our using some form of economic fundamentals.
Silver is also very careful to weight polls. 538 takes out some polls from their model and weight polls based on recency, sample size, and pollster rating. Polls are considered more important as we approach the election. Finally, Silver also makes an interesting note that in recent years, partisanship has become more important than fundamentals in their model. In other words, Silver is articulating that over time, economic fundamentals to him have become less useful to predicting elections. This is something I carefully considered in how to value the fundamentals that I put into my model. 

<br>
Next, I will briefly be comparing this approach to the Economist's model. The Economist states that their single best indicator is the generic ballot. Similarly, to the Economist, the generic ballot is the poll that I have added to my model this week. However, the Economist also relies on other polls for specific district races. The Economist also states that their fundamentals model includes considering how left or right leaning seats are based on previous elections. This is similar to Silver, who stated that he also chosen to start thinking about partisanship more than just economic fundamentals for his model. The Economist also uses campaign contributions to make these assesments about partisanship. Finally, they state that a part of getting closer to the final predictions is using district wide polls to re-assess their predictions from the other factors and get closer to the final result.
<br>
Now that we have taken a look at the two professional models, I will be getting a bit into my own model for this week. The biggest update for this week is that the model includes polling into the prediction. As both Silver and the Economist seem to hint at, fundamentals, particularly economic fundamentals, might not be the best way to predict outcomes. Last week, I certainly saw that economic fundamentals was not a great way to get a prediction based on my own results. Based on the work of Silver, I have also chosen to include partisanship more into my model by factoring previous election result into the model as well.
<br>
Ultimately, it is worth noting that both of these models are close together and show the GOP winning the house, but taking a thin margin.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(tidyverse)
library(stargazer)
setwd("/Users/yusufmian/Desktop/Election Analysis/Election-Blog")
generic2022 <- read.csv("538_generic_poll_2022.csv")
generic2022_select <- generic2022 %>% 
  select("pollster", "samplesize", "dem", "rep") %>% 
  rename("sample_size" = "samplesize") %>% 
  mutate(year=2022)
generic1942 <- read.csv("GenericPolls1942_2020.csv")
generic1942select <- generic1942 %>% 
  select("pollster", "sample_size", "dem", "rep", "year")
genericballot <- full_join(generic2022_select, generic1942select)
popularvote <- read.csv("H_popvote_df_fin.csv")
genericballotVote <- left_join(popularvote, genericballot,  by="year")
rdi_df <- read.csv("rdi_quarterly.csv")
gdp_df <- read.csv("GDP_quarterly.csv")
housevoteshare <- read.csv("house_popvote_seats.csv")
econdata <- left_join ( housevoteshare, gdp_df, by="year")
```

```{r}
genericballot2 <- genericballot %>% 
  mutate(poll_differenceDem=dem-rep)
genericballot3 <- genericballot2 %>% 
   group_by(year) %>% 
  mutate(mean_poll = mean(poll_differenceDem))
demVote <- genericballotVote %>%
  filter(party=="D") %>% 
  mutate(voteshareDifference = majorvote_pct- (100-majorvote_pct), poll_differenceDem=dem-rep)
demVote <- demVote %>% 
  group_by(year) %>% 
  mutate(mean_poll = mean(poll_differenceDem))
repVote <- genericballotVote %>%
  filter(party=="R") %>% 
  mutate(voteshareDifference = majorvote_pct- (100-majorvote_pct), poll_differenceRep=rep-dem)
repVote2 <- repVote %>%  
  group_by(year) %>% 
  mutate(mean_poll = mean(poll_differenceRep))
lm_dem_poll <- lm(voteshareDifference ~ mean_poll, data=demVote)
lm_dem_poll2 <- lm(voteshareDifference ~ poll_differenceDem, data=demVote)
stargazer(lm_dem_poll, title ="Polling Model", type="text")
```
```{r}
econ <- econdata %>% 
  filter(year%%4!=0, quarter_cycle=="5") %>% 
  mutate(voteshareDifference = H_incumbent_party_majorvote_pct- (100-H_incumbent_party_majorvote_pct))
lm_gdp <- lm(voteshareDifference ~ GDP_growth_qt, data=econ)
stargazer(lm_gdp, title="Fundamentals Model", type="text")

```
To briefly explain the updates I have made to my prediction model this week - as follows. <br>
For the polling aspect of my model - I compared the generic ballot, which Silver and The Economist model seem to rely on. I am using the generic ballots available from previous years and comparing the differences in margins in the generic ballots to the difference in two party vote shares in the election. For the 2022 election, I limited the polls to the beginning of August, or about 90 days before the election, because there were so many polls available by restricting this, they should be more meaningful as Silver seems to believe. I may revist this as we approach the election. Next, my fundamentals model is rather straightforward, in that it compares the difference in GDP in Quarter 5, or in the beginning of the election year. I considered using Quarter 6, but Quarter 5 seemed to be slightly more predictive. However, as I found last week and Silver and the Economist stressed, fundamentals are not as important and so I weighted them a lot less in my model. Finally, to account for partisanship and previous elections, I took an average of the previous 3 house elections, which included one year with GOP control, one Dem wave, and one close election. This will definitely be explored in the coming weeks to make this aspect of the model better, but for now it is what I am using to represent this aspect of the model. The weights I used were 40 percent polling, 40 percent partisanship/previous election results, and 20 percent fundamentals.

```{r}
demVote3 <- genericballotVote %>%
  filter(year>=2016, party=="D") %>% 
  summarize(meanDem = mean(majorvote_pct))
repVote3 <- repVote %>% 
  filter(year>=2016) %>% 
  summarize(meanRep = mean(majorvote_pct))
difference2016 <- demVote3$meanDem - repVote3$meanRep
demVotenew <- generic2022 [-c(1:929),] %>% 
  mutate(poll_differenceDem=dem-rep)
demVotenewclean <- demVotenew %>% 
  mutate(mean_poll=mean(poll_differenceDem))
gdpVotenew <-gdp_df %>% 
  filter(year==2022, quarter_cycle=="5") %>% 
  select(GDP_growth_qt)
gdpPrediction <- predict(lm_gdp, gdpVotenew)
pollingDemPrediction <- mean(predict(lm_dem_poll, demVotenewclean))
finalPrediction <-(0.4 * pollingDemPrediction) + (0.4 * difference2016) + (0.2 * gdpPrediction)
table <- matrix(c(finalPrediction, gdpPrediction, pollingDemPrediction, difference2016), ncol=1, byrow=TRUE)
rownames(table) <- c('Overall Prediction', 'Fundamentals Prediction', "Polling Prediction", "Previous Elections Prediction")
colnames(table) <- c(" ")
stargazer(table, title="Predictions (Democratic Predicted Margin of Win", type="text")
```


